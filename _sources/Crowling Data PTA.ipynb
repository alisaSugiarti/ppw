{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBENi+QKJ5zgdc+UdS7cbB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Nama  : Alisa Sugiarti\n","\n","NIM   : 200411100194\n","\n","\n","\n","\n","# **Crowling Data**\n","(22/8/2023 - 29/8/2023)\n","\n","Perintahnya:\n","1. Lakukan crawling data pada pta.trunojoyo.ac.id\n","2. data disimpan dalam bentuk .csv\n","3. data yang diambil : judul, nama penulis, pembimbing I, pembimbing II, abstrak"],"metadata":{"id":"lNvwDt0bMBnw"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","fak = '3'\n","page = 1\n","base_url = 'https://pta.trunojoyo.ac.id/c_search/byfac/{}/{}'\n","\n","# Membuka file CSV untuk menulis hasil scraping\n","with open('hasil_scraping.csv', 'w', newline='', encoding='utf-8') as csvfile:\n","    fieldnames = ['Judul', 'Penulis', 'Dosen Pembimbing I', 'Dosen Pembimbing II', 'Abstrak']\n","    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","    # Menulis header ke dalam file CSV\n","    writer.writeheader()\n","\n","    while True:\n","        url = base_url.format(fak, page)\n","        req = requests.get(url)\n","        soup = BeautifulSoup(req.text, 'html.parser')\n","        items = soup.find_all('li', attrs={'data-id': 'id-1'})\n","\n","        if not items:\n","            break\n","\n","        for it in items:\n","            data = {}\n","            title = it.find('a', class_='title').text\n","            data['Judul'] = title\n","            div_elements = it.find_all('div', style='padding:2px 2px 2px 2px;')\n","            for div in div_elements:\n","                span = div.find('span')\n","                if span:\n","                    span_text = span.get_text()\n","                    key, value = span_text.split(':', 1)\n","                    data[key.strip()] = value.strip()\n","\n","            # Mengambil link abstrak dari elemen dengan kelas 'gray button'\n","            abstrak_button = it.find('a', class_='gray button')\n","            if abstrak_button:\n","                abstrak_link = abstrak_button['href']\n","                abstrak_req = requests.get(abstrak_link)\n","                abstrak_soup = BeautifulSoup(abstrak_req.text, 'html.parser')\n","                abstrak = abstrak_soup.find('p', align='justify')\n","                if abstrak:\n","                    abstrak_text = abstrak.get_text(strip=True)\n","                    data['Abstrak'] = abstrak_text\n","                else:\n","                    data['Abstrak'] = \"Tidak ditemukan abstrak\"\n","\n","            # Menulis data ke dalam file CSV\n","            writer.writerow(data)\n","            print(\"Data berhasil ditambahkan:\", data)\n","\n","        page += 1\n","\n","print(\"Scraping selesai dan hasil disimpan dalam hasil_scraping.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1IoBLfzbiZ6d2ybo3Eqsb77cPrdiDHW5h"},"id":"fQ5iXii34aCK","executionInfo":{"status":"ok","timestamp":1692941597009,"user_tz":-420,"elapsed":1952442,"user":{"displayName":"20-194 Alisa Sugiarti","userId":"01231775848448837067"}},"outputId":"352264f7-a7c6-412b-c7dd-89f87ce10cf2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}